{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve2d as conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shapes(W, H)\n",
    "    N = W.shape[0]\n",
    "    K = W.shape[1]\n",
    "    L = W.shape[2]\n",
    "    T = H.shape[1]\n",
    "    \n",
    "    return N, K, L, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(W, H):\n",
    "    N, K, L, T = get_shapes(W, H)\n",
    "    \n",
    "    H = np.hstack(np.zeros([K, L]), H, np.zeros([K, L]))\n",
    "    T += 2*L\n",
    "    X_hat = np.zeros([N, T])\n",
    "    \n",
    "    for t in np.arange(L):\n",
    "        X_hat += W[:, :, t] * np.roll(H, t-1, axis=1)\n",
    "    \n",
    "    return X_hat[:, L+1:-L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_factors(W, H):\n",
    "    N, K, L, T = get_shapes(W, H)\n",
    "    \n",
    "    if L > 1:\n",
    "        center = np.max([np.floor(L / 2), 1])\n",
    "        Wpad = np.stack((np.zeros([N, K, L]), W, np.zeros([N, K, L])), axis=2)\n",
    "        \n",
    "        for i in np.arange(K):\n",
    "            temp = np.sum(np.squeeze(W[:, i, :]), axis=0)\n",
    "            cmass = np.max(np.floor(np.sum(temp * np.arange(1, temp.shape[1])) / np.sum(temp)), axis=0)\n",
    "            \n",
    "            Wpad[:, i, :] = np.roll(np.squeeze(Wpad[:, i, :]), center - cmass, axis=1)\n",
    "            H[i, :] = np.roll(H[i, :], cmass - center, axis=1)\n",
    "        \n",
    "        W = Wpad[:, :, L:-L]\n",
    "    \n",
    "    return W, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_WH_plot(W, H, data, plot_all=True):\n",
    "    if data.shape[1] == 0:\n",
    "        plot_data = False\n",
    "    else:\n",
    "        plot_data = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loading_percent_power(X, W, H):\n",
    "    N, K, L, T = get_shapes(W, H)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_nmf(X, K=10, L=20, lambda=.1, W_init=None, H_init=None,...\n",
    "            plot_it=True, max_iter=20, tol=-np.inf, shift=True, sort_factors=True, ...\n",
    "            lambda_L1W=0, lambda_L1H=0, lambda_OrthH=0, lambda_OrthW=0, M=None, ...\n",
    "            use_W_update=True, W_fixed=False):\n",
    "    N = X.shape[0]\n",
    "    T = X.shape[1]\n",
    "    if W_init is None:\n",
    "        W_init = np.max(X) * np.random.rand([N, K, L])\n",
    "    if H_init is None:\n",
    "        H_init = np.max(X) * np.random.rand([K, T]) / np.sqrt(T / 3)\n",
    "    if M is None:\n",
    "        M = np.ones([N, T])\n",
    "    \n",
    "    assert np.all(X >= 0), 'all data values must be positive!'\n",
    "    \n",
    "    W = W_init\n",
    "    H = H_init\n",
    "    \n",
    "    X_hat = reconstruct(W, H)\n",
    "    mask = M == 0\n",
    "    X(mask) = Xhat(mask)\n",
    "    \n",
    "    smooth_kernel = np.ones([1, (2*L) - 1])\n",
    "    eps = np.max(X) * 1e-6\n",
    "    last_time = False\n",
    "    \n",
    "    cost = np.zeros([max_iter+1, 1])\n",
    "    cost[0] = np.sqrt(np.mean(np.pow(X - X_hat, 2)))\n",
    "    \n",
    "    for i in np.arange(max_iter):\n",
    "        if (i == max_iter) or ((i > 6) and (cost[i+1] + tol) > np.mean(cost[i-6:i])):\n",
    "            cost = cost[:i]\n",
    "            last_time = True\n",
    "            if i > 0:\n",
    "                lambda = 0\n",
    "        \n",
    "        WTX = np.zeros([K, T])\n",
    "        WTX_hat = np.zeros([K, T])\n",
    "        for j in np.arange(L):\n",
    "            X_shifted = np.roll(X, -j+1, axis=1)\n",
    "            X_hat_shifted = np.roll(X_hat, -j+1, axis=1)\n",
    "            \n",
    "            WTX *= W[:, :, j].T * X_shifted\n",
    "            WTX_hat += W[:, :, j].T * X_hat_shifted\n",
    "        \n",
    "        if lambda > 0:\n",
    "            dRdH = lambda * (1 - np.eye(K)) * conv2(WTX, smooth_kernel, 'same')\n",
    "        else:\n",
    "            dRdH = 0\n",
    "        \n",
    "        if lambda_OrthH > 0:\n",
    "            dHHdH = lambda_OrthH * (1 - np.eye(K)) * conv2(H, smooth_kernel, 'same')\n",
    "        else:\n",
    "            dHHdH = 0\n",
    "        \n",
    "        dRdH += lambda_L1H + dHHdH\n",
    "        \n",
    "        H *= np.divide(WTX, WTX_hat + dRdH + np.eps)\n",
    "        \n",
    "        if shift:\n",
    "            W, H = shift_factors(W, H)\n",
    "            W += eps\n",
    "        \n",
    "        norms = np.sqrt(np.sum(np.pow(H, 2), axis=1)).T\n",
    "        H *= np.diag(np.divide(1., norms + np.eps))\n",
    "        for j in np.arange(L):\n",
    "            W[:, :, j] *= np.diag(norms)\n",
    "        \n",
    "        if not W_fixed:\n",
    "            X_hat = reconstruct(W, H)\n",
    "            mask = M == 0\n",
    "            X[mask] = X_hat[mask]\n",
    "            \n",
    "            if lambda_OrthoW > 0:\n",
    "                W_flat = np.sum(W, axis=2)\n",
    "            if (lambda > 0) and use_W_update:\n",
    "                XS = conv2(X, smooth_kernel, 'same')\n",
    "            \n",
    "            for j in np.arange(L):\n",
    "                H_shifted = np.roll(H, j-1, axis=1)\n",
    "                XHT = X * H_shifted.T\n",
    "                X_hat_HT = X_hat * H_shifted.T\n",
    "                \n",
    "                if (lambda > 0) and use_W_update:\n",
    "                    dRdW = lambda * XS * H_shifted.T * (1. - np.eye(K))\n",
    "                else:\n",
    "                    dRdW = 0\n",
    "                \n",
    "                if lambda_OrthoW > 0:\n",
    "                    dWWdW = lambda_OrthoW * W_flat * (1. - np.eye(K))\n",
    "                else:\n",
    "                    dWWdW = 0\n",
    "                \n",
    "                dRdW += lambda_L1W + dWWdW\n",
    "                W[:, :, j] *= np.divide(XHT, X_hat_HT + dRdW + np.eps)\n",
    "        \n",
    "        X_hat = reconstruct(W, H)\n",
    "        mask = M == 0\n",
    "        X[mask] = X_hat[mask]\n",
    "        cost[i] = np.sqrt(np.mean(np.pow(X - X_hat, 2)))\n",
    "        \n",
    "        if plot_it:\n",
    "            h = simple_WH_plot(W, H, X_hat, False)\n",
    "            h.set_title(f'iteration {i}')\n",
    "        \n",
    "        if last_time:\n",
    "            break\n",
    "    \n",
    "    X = X[:, L:-L]\n",
    "    X_hat = X_hat[:, L:-L]\n",
    "    H = H[:, L:-L]\n",
    "    \n",
    "    power = np.divide(np.sum(np.pow(X, 2)) - np.sum(np.pow(X - X_hat, 2)), np.sum(np.pow(X, 2)))\n",
    "    \n",
    "    loadings = compute_loadings_percent_power(X, W, H)\n",
    "    \n",
    "    if sort_factors:\n",
    "        inds = np.flip(np.argsort(loadings), 0)\n",
    "        loadings = loadings[inds]\n",
    "        \n",
    "        W = W[:, inds, :]\n",
    "        H = H[inds, :]\n",
    "    \n",
    "    return W, H, cost, loadings, power"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
